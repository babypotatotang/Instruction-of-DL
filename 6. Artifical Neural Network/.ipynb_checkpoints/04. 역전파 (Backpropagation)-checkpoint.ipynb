{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "358f70ad",
   "metadata": {},
   "source": [
    "인공 신경망이 순전파 과정을 진행하여 예측값과 실제값의 오차를 계산하였을때 어떻게 역전파 과정에서 경사하강법을 사용하여 가중치를 업데이트하는지 직접 계산을 통해 이해해보자."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c74bcb9",
   "metadata": {},
   "source": [
    "# 1. 인공신경망의 이해 (Neural Network Overview)\n",
    "\n",
    "* 우선 예제를 위해 사용될 인공신명감은 다음과 같음. 역전파의 이해를 위해서 여기서  사용할 인공신경망은 **입력층, 은닉층, 출력층** 이렇게 3개의 층을 가짐. 또, 해당 인공신경망은 두 개의 입력과 두 개의 은닝층 뉴런, 두 개의 출력층 뉴런을 사용함.\n",
    "* 모든 뉴런은 활성화 함수로 시그모이드 함수를 사용함. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4e2ed87",
   "metadata": {},
   "source": [
    "![](Photo/(06-04)1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7add8180",
   "metadata": {},
   "source": [
    "* 위의 그림은 여기서 사용할 인공신경망의 모습\n",
    "* 은닉층과 출력층의 모든 뉴런에서 변수 z가 존재하는데, 변수 z는 **이전 층의 모든 입력이 각각의 가중치와 곱해진 값들이 모두 더해진 가중합**을 의미하며, 이 값은 뉴런에서 아직 활성함수(시그모이드 함수)를 거치지 않은 상태임. \n",
    "    - 즉, 활성화 함수의 입력을 의미 \n",
    "* z 우측의 | 를 지나서 존재하는 변수 h 또는 o는 z가 시그모이드 함수를 지난 후의 값으로 뉴런의 출력을 의미함.\n",
    "* 이번 예제에서는 인공 신경망에 존재하는 모든 가중치 W에 대해서 역전파를 통해 업데이트하는 것을 목표로 진행하며, 편향 b는 고려하지 않음. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b789d74",
   "metadata": {},
   "source": [
    "# 2. 순전파 (Forward Propagation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdcfed5b",
   "metadata": {},
   "source": [
    "![](Photo/(06-04)2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57f618de",
   "metadata": {},
   "source": [
    "* 우선 순전파를 진행해보자. 위의 그림에서 소수점 앞의 0은 생략하였으며, 파란색 숫자는 입력값을, 빨간색 숫자는 각 가중치의 값을 의미함. \n",
    "* 각 입력은 입력층에서 은닉층 방향으로 향하면서 각 입력에 해당하는 가중치와 곱해지고, 결과적으로 가중합으로 계산되어 은닉층 뉴런의 시그모이드 함수의 입력값이 됨. $z_1$과 $z_2$는 시그모이드 함수의 입력으로 사용되는 각각의 값에 해당됨.\n",
    "\n",
    "\n",
    "$$z_1 = W_1x_1 + W_2x_2 = 0.3 x 0.1 + 0.25 x 0.2 = 0.08$$\n",
    "$$z_2 = W_3x_1 + W_4x_2 = 0.4 x 0.1 + 0.35 x 0.2 = 0.11$$\n",
    "\n",
    "* $z_1$과 $z_2$는 각각의 은닉층 뉴런에서 시그모이드함수를 지나게 되는데, 시그모이드 함수가 리턴하는 결과 값은 은닉층 뉴런의 최종 출력값이 됨. 식에서는 각각 $h_1$과 $h_2$에 해당되며 결과는 아래와 같음. \n",
    "\n",
    "$$h_1 = sigmoid(z_1) = 0.51998934$$\n",
    "$$h_2 = sigmoid(z_2) = 0.52747230$$\n",
    "\n",
    "* $h_1$과 $h_2$ 이 두 값은 다시 출력층의 뉴런으로 향하는데, 이때 다시 각각의 값에 해당되는 가중치와 곱해지고, 다시 가중합이 되어 출력층 뉴런의 시그모이드 함수의 입력값이 됨. 식에서는 $z_3$과 $z_4$에 해당됨. \n",
    "\n",
    "$$z_3 = W_5h_1 + W_6h_2 = 0.45 x h_1 + 0.4 x h_2 = 0.44498412$$\n",
    "$$z_4 = W_7h_1 + W_8h_2 = 0.7 x h_1 + 0.6 x h_2 = 0.68047582$$\n",
    "\n",
    "*$z_3$과 $z_4$이 출력층 뉴런에서 시그모이드 함수를 지난 값은 이 인공신경망이 최종적으로 계산한 출력값으로, 실제 값을 예측하기 위한 예측값으로 볼 수 있음. \n",
    "\n",
    "$$o_1 = sigmoid(z_3) = 0.60944600$$\n",
    "$$o_2 = sigmoid(z_4) = 0.66384491$$\n",
    "\n",
    "* 이제 해야할 일은 예측값과 실제값의 오차를 계산하기 위해 손실함수(Loss Fuction)을 사용하는 것임. 본 예제에서는 **평균 제곱 오차 MSE**를 손실함수로 사용함. 식에서는 실제값을 target이라고 표현하였으며, 순전파를 통해 나온 예측값을 output으로 표현함. 그리고 각 오차를 모두 더하면 전체 오차 $E_{total}$이 됨. \n",
    "\n",
    "$$E_{o1} =  \\frac{1}{2}(target_{o1} - output_{o1})^2 = 0.02193381$$\n",
    "$$E_{o2} =  \\frac{1}{2}(target_{o2} - output_{o2})^2 = 0.0203809$$\n",
    "$$E_{total} =  E_{o1} + E_{o2} = 0.02397190$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6283642",
   "metadata": {},
   "source": [
    "# 3. 역전파 1단계 (BackPropagation Step 1)\n",
    "\n",
    "* 순전파가 입력층에서 출력층으로 향한다면 역전파는 반대로 **출력층에서 입력층 방향**으로 계산하면서, 가중치를 업데이트함. 출력층 바로 이전의 은닉층을 N층이라고 할때, **출력층과 N층 사이의** 가중치를 업데이트 하는 단계를 역전파 1단계, 그리고 **N층과 N층의 이전층 사이의** 가중치를 업데이트 하는 단계를 역전파 2단계라고 하자. \n",
    "![](Photo/(06-04)3.png)\n",
    "\n",
    "* 역전파 1단계에서 업데이트해야하는 가중치는 $W_5, W_6, W_7, W_8$으로 총 4개임. 원리 자체는 동일하므로, 우선 $W_5$에 대해 먼저 업데이트를 진행함. \n",
    "\n",
    "* 경사하강법을 수행하여 가중치를 업데이트하고자 $\\frac{\\partial E_{total}}{\\partial W_5} $를 계산하겠음. 위 식을 계산하려면 **미분의 연쇄 법칙**에 따라서 아래와 같이 풀어 쓸 수 있음. \n",
    "\n",
    "$$\\frac{\\partial E_{total}}{\\partial W_5} = \\frac{\\partial E_{total}}{\\partial o_1} * \\frac{\\partial o_1}{\\partial z_3} * \\frac{\\partial z_3}{\\partial W_5}$$\n",
    "\n",
    "* 위 식에서 우변의 세 개의 각 항에 대해서 순서대로 계산해보자. 우선 첫번째 항에 대해서 계산해보겠음.  \n",
    "\n",
    "$$E_{total}= \\frac{1}{2}(traget_{o1} - output_{o1})^2 + \\frac{1}{2}(target_{o2} - output_{o2})^2$$\n",
    "$$\\frac{\\partial E_{total}}{\\partial o_1} = 2 * \\frac{1}{2}(target_{o1} - output_{o1})^{2-1} * (-1) + 0 = -(target_{o1} - output_{o1} = -(0.4 - 0.609446) = 0.209446$$\n",
    "\n",
    "* 이제 두번째 항을 보면, $o_1$이라는 값은 시그모이드 함수의 출력값임. 그런데 시그모이드 함수의 미분은 f(x) * (1-f(x))임. 두번째 항은 시그모이드 함수의 출력이므로, 다음과 같이 식을 풀어쓸 수 있음. \n",
    "\n",
    "$$\\frac{ \\partial o_1}{ \\partial z_3} = o_1 * (1-o_1) = 0.609446 * (1-0.609446) = 0.23802157$$\n",
    "\n",
    "* 마지막으로 세번째 항은 $h_1$의 값과 동일하게 쓸 수 있음. \n",
    "$$\\frac{\\partial z_3}{\\partial W_5} = h_1 = 0.51998934$$\n",
    "\n",
    "* 위의 세가지 단계를 나눠서 나온 결과로, 모두 곱해주면 답이 나옴. \n",
    "\n",
    "$$\\frac{\\partial E_{total}}{\\partial W_5} = 0.209446 x 0.23802157 * 0.51998934 = 0.02492286$$\n",
    "\n",
    "* 앞서 배웠던 경사 하강법을 통해 가중치를 업데이트하겠음. \n",
    "$$W_5^+ = W_5 - \\alpha \\frac{\\partial E_{total}}{\\partial W_5} = 0.45 - 0.5 * 0.02592286 = 0.43703857$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "464a968a",
   "metadata": {},
   "source": [
    "# 4. 역전파 2단계 (BackPropagation Step 2)\n",
    "\n",
    "\n",
    "![](Photo/(06-04)4.png)\n",
    "* 1단계를 완료하였다면 이제 입력층 방향으로 이동하면서 다시 계산을 이어감. \n",
    "* 빨간색 화살표는 순전파의 정반대 방향인 역전파 방향을 보여줌. \n",
    "* 1단계와 마찬가지고 각 가중치를 업데이트할 수 있음. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7859989",
   "metadata": {},
   "source": [
    "# 5. 결과 확인 \n",
    "* 업데이트된 가중치에 대해서 한 번 순전파를 진행하여 오차가 감소하였는지 확인해보겠음. \n",
    "\n",
    "\n",
    "$$o_1 = sigmoid(z_3) = 0.60617688$$\n",
    "$$o_2 = sigmoid(z_4) = 0.66295848$$\n",
    "\n",
    "$$E_{o1} = \\frac{1}{2}(target_{o1} - output_{o1})^2 = 0.02125445$$\n",
    "$$E_{o2} = \\frac{1}{2}(target_{o2} - output_{o2})^2 = 0.00198189$$\n",
    "\n",
    "$$E_{total} = E_{o1} + E_{o2} = 0.02323624$$\n",
    "\n",
    "* 기존의 전체 오차였던 0.02397190보다 감소한 것을 확인할 수 있음. 즉, 인공신경망의 학습은 오차를 최소화하는 가중치를 찾는 것을 목적으로, 순전파와 역전파를 반복하는 것을 말함. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
