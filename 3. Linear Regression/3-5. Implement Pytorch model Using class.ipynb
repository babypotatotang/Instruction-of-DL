{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <u>**5. 클래스로 파이토치 모델 구현하기**</u>\n",
    "* 파이토치의 구현체들은 대부분 모델을 생성할때 클래스(Class)를 사용함. \n",
    "* 선형 회귀를 클래스로 구현. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **1. 모델을 클래스로 구현하기**\n",
    "### **단순선형회귀모델**\n",
    "* 기존의 **단순선형회귀모델**은 다음과 같이 구현함. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델을 선언 및 초기화\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "model=nn.Linear(1,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 클래스 구현은 다음과 같음. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearRegressionModel(nn.Module): #torch.nn.Module을 상속받는 파이썬 클래스\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.linear=nn.Linear(1,1) #단순선형회귀\n",
    "    \n",
    "    def forward(self,x):\n",
    "        return self.linear(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=LinearRegressionModel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* `super()`함수를 불러 `nn.Module` 클래스의 속성을 상속받아 초기화\n",
    "  * 파이썬에서 객체가 갖는 속성값을 초기화\n",
    "  * 객체가 생성될때 자동으로 호출됨. \n",
    "* `forward()`함수는 모델이 학습데이터를 입력받아서 **forward 연산**을 진행\n",
    "  * `model`객체를 데이터와 함께 호출하면 자동으로 실행됨.\n",
    "  * $H(x)$ 식에 입력 $x$로부터 예측된 $y$를 얻는 것을 forward 연산이라고함. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **다중선형회귀모델**\n",
    "* 기존의 **다중선형회귀모델**은 다음과 같이 구현. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "model=nn.Linear(3,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 클래스로 구현하면 다음과 같음. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultivariateLinearRegressionModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.linear=nn.Linear(3,1)\n",
    "    \n",
    "    def forward(self,x):\n",
    "        return self.linear(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=MultivariateLinearRegressionModel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **2. 단순 선형회귀 클래스로 구현하기**\n",
    "* 모델을 클래스로 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x1e4b3ea03d0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "torch.manual_seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train=torch.FloatTensor([[1],[2],[3]])\n",
    "y_train=torch.FloatTensor([[2],[4],[6]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearRegressionModel(nn.Module): #torch.nn.Module을 상속받는 파이썬 클래스\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.linear=nn.Linear(1,1) #단순선형회귀\n",
    "    \n",
    "    def forward(self,x):\n",
    "        return self.linear(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=LinearRegressionModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer=torch.optim.SGD(model.parameters(),lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch    0/2000, Cost:13.103541\n",
      "Epoch  100/2000, Cost:0.002791\n",
      "Epoch  200/2000, Cost:0.001724\n",
      "Epoch  300/2000, Cost:0.001066\n",
      "Epoch  400/2000, Cost:0.000658\n",
      "Epoch  500/2000, Cost:0.000407\n",
      "Epoch  600/2000, Cost:0.000251\n",
      "Epoch  700/2000, Cost:0.000155\n",
      "Epoch  800/2000, Cost:0.000096\n",
      "Epoch  900/2000, Cost:0.000059\n",
      "Epoch 1000/2000, Cost:0.000037\n",
      "Epoch 1100/2000, Cost:0.000023\n",
      "Epoch 1200/2000, Cost:0.000014\n",
      "Epoch 1300/2000, Cost:0.000009\n",
      "Epoch 1400/2000, Cost:0.000005\n",
      "Epoch 1500/2000, Cost:0.000003\n",
      "Epoch 1600/2000, Cost:0.000002\n",
      "Epoch 1700/2000, Cost:0.000001\n",
      "Epoch 1800/2000, Cost:0.000001\n",
      "Epoch 1900/2000, Cost:0.000000\n",
      "Epoch 2000/2000, Cost:0.000000\n"
     ]
    }
   ],
   "source": [
    "nb_epochs=2000\n",
    "for epoch in range(nb_epochs+1):\n",
    "\n",
    "    #H(x)계산\n",
    "    prediction=model(x_train)\n",
    "\n",
    "    #cost 계산\n",
    "    cost=F.mse_loss(prediction,y_train)\n",
    "\n",
    "    #cost로 H(x) 개선 및 update\n",
    "    optimizer.zero_grad()\n",
    "    cost.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if epoch%100==0:\n",
    "        print('Epoch {:4d}/{}, Cost:{:.6f}'.format(epoch,nb_epochs,cost.item()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **3. 다중선형회귀클래스로 구현하기**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x1e4b3ea03d0>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "torch.manual_seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train=torch.FloatTensor([[73,80,75],\n",
    "                           [93,88,93],\n",
    "                           [89,91,90],\n",
    "                           [96,98,100],\n",
    "                           [73,66,70]])\n",
    "y_train=torch.FloatTensor([[152],[185],[180],[196],[142]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultivariateLinearRegressionModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.linear=nn.Linear(3,1)\n",
    "    \n",
    "    def forward(self,x):\n",
    "        return self.linear(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=MultivariateLinearRegressionModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer=torch.optim.SGD(model.parameters(),lr=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch    0/2000 Cost:31667.599609\n",
      "Epoch  100/2000 Cost:0.225993\n",
      "Epoch  200/2000 Cost:0.223911\n",
      "Epoch  300/2000 Cost:0.221941\n",
      "Epoch  400/2000 Cost:0.220059\n",
      "Epoch  500/2000 Cost:0.218271\n",
      "Epoch  600/2000 Cost:0.216575\n",
      "Epoch  700/2000 Cost:0.214950\n",
      "Epoch  800/2000 Cost:0.213413\n",
      "Epoch  900/2000 Cost:0.211952\n",
      "Epoch 1000/2000 Cost:0.210559\n",
      "Epoch 1100/2000 Cost:0.209230\n",
      "Epoch 1200/2000 Cost:0.207967\n",
      "Epoch 1300/2000 Cost:0.206762\n",
      "Epoch 1400/2000 Cost:0.205618\n",
      "Epoch 1500/2000 Cost:0.204529\n",
      "Epoch 1600/2000 Cost:0.203481\n",
      "Epoch 1700/2000 Cost:0.202486\n",
      "Epoch 1800/2000 Cost:0.201539\n",
      "Epoch 1900/2000 Cost:0.200634\n",
      "Epoch 2000/2000 Cost:0.199770\n"
     ]
    }
   ],
   "source": [
    "nb_epochs=2000\n",
    "for epoch in range(nb_epochs+1):\n",
    "    #H(x) 계산\n",
    "    prediction=model(x_train)\n",
    "\n",
    "    #cost 계산\n",
    "    cost=F.mse_loss(prediction,y_train)\n",
    "\n",
    "    #cost로 H(x) 개선\n",
    "    optimizer.zero_grad()\n",
    "    cost.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if epoch%100==0:\n",
    "        print('Epoch {:4d}/{} Cost:{:.6f}'.format(epoch,nb_epochs,cost.item()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.13 ('deeplearning')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "33bb709aa52d0f1c012e153b74c2c585d1723b1d162db1a778a7381b9d9efdce"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
